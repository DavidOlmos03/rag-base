# RAG Base as a Service (RAGaaS)
## Arquitectura Base MultipropÃ³sito con FastAPI, Open Source y Multi-LLM

---

## ğŸ§  Rol del sistema

ActÃºa como un **arquitecto senior de sistemas de IA**, especializado en:

- Retrieval-Augmented Generation (RAG)
- FastAPI y arquitecturas async
- Docker y despliegue en producciÃ³n
- Sistemas multi-tenant y multi-modelo
- Enfoque **open-source first**, optimizaciÃ³n de costos y escalabilidad futura

---

## ğŸ¯ Objetivo general

DiseÃ±ar y construir un **RAG as a Service (RAGaaS)** implementado en **Python (FastAPI)** que funcione como un **nÃºcleo reutilizable**, preparado para ser consumido y adaptado por mÃºltiples proyectos independientes, tales como:

- Sistemas legales (abogados)
- Proyectos acadÃ©micos / universitarios
- Plataformas de divulgaciÃ³n cientÃ­fica

Este proyecto debe **limitarse exclusivamente al RAG base**, sin incluir lÃ³gica especÃ­fica de dominio.

---

## ğŸ§© Alcance del proyecto

El sistema debe:

- Implementar **solo el core del RAG**
- Ser **agnÃ³stico al dominio**
- Ser **agnÃ³stico al proveedor de LLM**
- Permitir extensiÃ³n futura sin refactorizaciÃ³n mayor

Cada proyecto consumidor podrÃ¡ posteriormente:
- Definir prompts especÃ­ficos
- Ajustar pipelines
- Elegir proveedor y modelo LLM
- Configurar polÃ­ticas propias

---

## ğŸ—ï¸ Stack tecnolÃ³gico

### Backend
- Python 3.11+
- FastAPI (async-first)
- Pydantic v2
- Arquitectura modular

### Enfoque
- Open-source first
- Bajo costo operativo
- Evitar lock-in con proveedores

---

## ğŸ§  Arquitectura RAG Base

El RAG debe estar desacoplado del modelo y del proveedor.

### Pipeline recomendado

Document Loader
â†“
Chunker
â†“
Embedding Generator
â†“
Vector Store (Qdrant)
â†“
Retriever
â†“
Context Builder
â†“
Prompt Adapter
â†“
LLM Client (OpenAI / Claude / DeepSeek / Ollama)


---

## ğŸ“‚ Componentes del RAG Core

### 1. Ingesta de documentos
- PDF
- TXT
- DOCX
- Preparado para OCR en el futuro

### 2. Chunking
- Configurable:
  - TamaÃ±o
  - Overlap
- Independiente del dominio

### 3. Embeddings
- **Open-source**
- Independientes del proveedor LLM

#### Modelos recomendados
- `bge-m3`
- `e5-large`

---

## ğŸ“¦ Vector Database

### Requerimientos
- Open-source
- Self-hosted
- Soporte de metadatos
- Namespaces / collections

### ElecciÃ³n recomendada
- **Qdrant**

Uso de metadatos:
- `project_id`
- `document_id`
- `version`
- `source`

---

## ğŸ¤– Soporte Multi-LLM (crÃ­tico)

El sistema debe permitir cambiar de proveedor **sin reindexar documentos**.

### Proveedores soportados

#### APIs externas
- OpenAI (ChatGPT)
- Anthropic (Claude)
- DeepSeek
- Otros compatibles

#### Modelos locales
- **Ollama**
- SelecciÃ³n explÃ­cita del modelo (ej: `llama3`, `mistral`)

---

## ğŸ”Œ Endpoint de configuraciÃ³n de LLM

Debe existir un endpoint para registrar y seleccionar dinÃ¡micamente el proveedor LLM.

### Capacidades requeridas
- Registrar API Key
- Registrar Base URL
- Seleccionar proveedor:
  - `openai`
  - `claude`
  - `deepseek`
  - `ollama`
- Seleccionar modelo
- Elegir entre:
  - API externa
  - Modelo local

âš ï¸ El core del RAG **no debe depender directamente del proveedor**, solo de un adapter.

---

## ğŸ§© DiseÃ±o por interfaces (recomendado)

Ejemplos de interfaces base:

- `LLMClient`
- `EmbeddingProvider`
- `VectorStore`
- `Retriever`

Esto garantiza:
- Bajo acoplamiento
- FÃ¡cil extensiÃ³n
- Mantenibilidad

---

## ğŸ³ DockerizaciÃ³n (obligatoria)

El proyecto debe estar completamente dockerizado.

### Entornos

#### Desarrollo
- Hot reload
- Logs detallados
- VolÃºmenes montados

#### ProducciÃ³n
- Multi-stage build
- Imagen optimizada
- Variables de entorno
- SeparaciÃ³n clara de servicios

### Archivos requeridos
- `Dockerfile.dev`
- `Dockerfile.prod`
- `docker-compose.dev.yml`
- `docker-compose.prod.yml`

### Servicios esperados
- API (FastAPI)
- Qdrant
- Ollama (opcional)

---

## ğŸ’° OptimizaciÃ³n de costos

- Uso prioritario de herramientas open-source
- Embeddings locales
- Ollama para:
  - Desarrollo
  - Pruebas
  - Casos de bajo presupuesto
- Escalado bajo demanda

---

## ğŸ“ Estructura de proyecto sugerida

```text
rag_base/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ docker/
â”œâ”€â”€ docker-compose.dev.yml
â”œâ”€â”€ docker-compose.prod.yml
â”œâ”€â”€ Dockerfile.dev
â”œâ”€â”€ Dockerfile.prod
â””â”€â”€ README.md

